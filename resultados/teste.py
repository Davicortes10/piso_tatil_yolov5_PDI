import cv2
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

# Lista de classes do modelo YOLOv5 (ajuste conforme necessÃ¡rio)
CLASS_NAMES = ["frente", "parar", "direita", "placa_faltante", "esquerda"
]  # Modifique conforme o seu modelo

def detect_piso_tatil(image_path, model_path="yolov5_tf_select.tflite", confidence_threshold=0.5):
    """
    Detecta piso tÃ¡til em uma imagem usando um modelo YOLOv5 convertido para TensorFlow Lite.

    Args:
        image_path (str): Caminho da imagem a ser processada.
        model_path (str): Caminho do modelo TFLite convertido.
        confidence_threshold (float): Limite de confianÃ§a para exibir as detecÃ§Ãµes.

    Returns:
        None. Exibe a imagem com as detecÃ§Ãµes e imprime as classes detectadas.
    """
    # ğŸš€ Carregar o modelo TFLite
    interpreter = tf.lite.Interpreter(model_path=model_path)
    interpreter.allocate_tensors()

    # ğŸ“ Obter detalhes da entrada e saÃ­da do modelo
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()

    # ğŸ“ Formato esperado pelo modelo (1, 3, 640, 640)
    input_shape = input_details[0]['shape']
    _, model_channels, model_height, model_width = input_shape

    print(f"ğŸ“ Modelo espera: {input_shape}")

    # ğŸ“¸ Carregar a imagem original
    image = cv2.imread(image_path)
    if image is None:
        raise FileNotFoundError(f"âŒ Erro: Imagem nÃ£o encontrada: {image_path}")

    original_height, original_width, _ = image.shape  # Tamanho original da imagem

    # ğŸ“ Redimensionar a imagem para o tamanho esperado pelo modelo
    image_resized = cv2.resize(image, (model_width, model_height))
    image_rgb = cv2.cvtColor(image_resized, cv2.COLOR_BGR2RGB)  # Converter para RGB

    # ğŸ”„ **Converter a imagem para o formato do modelo** (1, 3, 640, 640)
    image_input = np.transpose(image_rgb, (2, 0, 1))  # De (640, 640, 3) -> (3, 640, 640)
    image_input = np.expand_dims(image_input, axis=0).astype(np.float32) / 255.0  # Normalizar e expandir dimensÃ£o

    # ğŸ” Validar entrada antes de passar para o modelo
    print(f"ğŸ“ Formato da entrada da imagem: {image_input.shape}")

    # ğŸš€ Definir entrada do modelo corretamente
    interpreter.set_tensor(input_details[0]['index'], image_input)

    # âš¡ Executar a inferÃªncia
    interpreter.invoke()

    # ğŸ“Œ Obter saÃ­da do modelo (YOLOv5 pode ter mÃºltiplas saÃ­das)
    output_data = interpreter.get_tensor(output_details[0]['index'])

    print(f"ğŸ“Š SaÃ­da bruta do modelo: {output_data.shape}")

    # ğŸ› ï¸ Processar detecÃ§Ãµes
    def process_detections(output_data, model_width, model_height, original_width, original_height):
        """ Processa os resultados da inferÃªncia e retorna as caixas detectadas e as classes. """
        detections = []
        detected_classes = set()  # Armazena as classes detectadas

        for detection in output_data[0]:
            confidence = detection[4]  # ConfianÃ§a do objeto detectado
            if confidence > confidence_threshold:
                x_center, y_center, w, h = detection[:4]  # Coordenadas normalizadas (0 a 1)

                # Identificar a classe detectada
                class_id = int(np.argmax(detection[5:]))  # Pega a classe com maior score
                class_name = CLASS_NAMES[class_id] if class_id < len(CLASS_NAMES) else f"ID-{class_id}"
                detected_classes.add(class_name)

                # Converter para coordenadas no modelo (640x640)
                x_center *= model_width
                y_center *= model_height
                w *= model_width
                h *= model_height

                # Converter para coordenadas na imagem original
                x1 = int((x_center - w / 2) * (original_width / model_width))
                y1 = int((y_center - h / 2) * (original_height / model_height))
                x2 = int((x_center + w / 2) * (original_width / model_width))
                y2 = int((y_center + h / 2) * (original_height / model_height))

                detections.append((x1, y1, x2, y2, confidence, class_name))

        return detections, detected_classes

    # ğŸ“Œ Obter detecÃ§Ãµes corrigidas e classes detectadas
    detections, detected_classes = process_detections(output_data, model_width, model_height, original_width, original_height)

    print(f"âœ… NÃºmero de detecÃ§Ãµes: {len(detections)}")
    if len(detections) > 0:
        print(f"ğŸ“‹ Primeira detecÃ§Ã£o: {detections[0]}")  # DepuraÃ§Ã£o

    # ğŸ·ï¸ Exibir classes detectadas
    print(f"ğŸ¯ Classes detectadas: {', '.join(detected_classes) if detected_classes else 'Nenhuma'}")

    # ğŸ“¸ Exibir a imagem com as detecÃ§Ãµes
    for (x1, y1, x2, y2, conf, class_name) in detections:
        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(image, f"{class_name} {conf:.2f}", (x1, y1 - 5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # ğŸ–¼ï¸ Mostrar a imagem resultante
    plt.figure(figsize=(8, 6))
    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
    plt.axis("off")
    plt.title("DetecÃ§Ã£o de Piso TÃ¡til")
    plt.show()

# ğŸ› ï¸ Testar a funÃ§Ã£o com a imagem corrigida
detect_piso_tatil("datasets/images/train/Frame 562.png")
